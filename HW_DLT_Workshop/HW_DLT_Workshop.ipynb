{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69160d17",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "## Question 1. dlt Version\n",
    "\n",
    "In this homework, we will load the data from our FAQ to Qdrant\n",
    "\n",
    "Let's install dlt with Qdrant support and Qdrant client:\n",
    "\n",
    "```bash\n",
    "pip install -q \"dlt[qdrant]\" \"qdrant-client[fastembed]\"\n",
    "```\n",
    "\n",
    "What's the version of dlt that you installed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5125bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dlt\n",
    "dlt.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082002f5",
   "metadata": {},
   "source": [
    "The version of dlt installed is '1.12.3'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48893395",
   "metadata": {},
   "source": [
    "\n",
    "## dlt Resourse\n",
    "\n",
    "For reading the FAQ data, we have this helper function:\n",
    "\n",
    "```python\n",
    "def zoomcamp_data():\n",
    "    docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "    docs_response = requests.get(docs_url)\n",
    "    documents_raw = docs_response.json()\n",
    "\n",
    "    for course in documents_raw:\n",
    "        course_name = course['course']\n",
    "\n",
    "        for doc in course['documents']:\n",
    "            doc['course'] = course_name\n",
    "            yield doc\n",
    "```\n",
    "\n",
    "Annotate it with `@dlt.resource`. We will use it when creating\n",
    "a dlt pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ba876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate the function with dlt.resource\n",
    "import requests\n",
    "\n",
    "@dlt.resource(write_disposition=\"replace\", name=\"zoomcamp_data\")\n",
    "def zoomcamp_data():\n",
    "    docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "    docs_response = requests.get(docs_url)\n",
    "    documents_raw = docs_response.json()\n",
    "\n",
    "    for course in documents_raw:\n",
    "        course_name = course['course']\n",
    "\n",
    "        for doc in course['documents']:\n",
    "            doc['course'] = course_name\n",
    "            yield doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c7ae94",
   "metadata": {},
   "source": [
    "## Question 2. dlt pipeline\n",
    "\n",
    "Now let's create a pipeline. \n",
    "\n",
    "We need to define a destination for that. Let's use the `qdrant` one:\n",
    "\n",
    "```python\n",
    "from dlt.destinations import qdrant\n",
    "\n",
    "qdrant_destination = qdrant(\n",
    "  qd_path=\"db.qdrant\", \n",
    ")\n",
    "```\n",
    "\n",
    "In this case, we tell dlt (and Qdrant) to create a folder with\n",
    "our data, and the name for it will be `db.qdrant`\n",
    "\n",
    "Let's run it:\n",
    "\n",
    "```python\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"zoomcamp_pipeline\",\n",
    "    destination=qdrant_destination,\n",
    "    dataset_name=\"zoomcamp_tagged_data\"\n",
    "\n",
    ")\n",
    "load_info = pipeline.run(zoomcamp_data())\n",
    "print(pipeline.last_trace)\n",
    "```\n",
    "\n",
    "How many rows were inserted into the `zoomcamp_data` collection?\n",
    "\n",
    "Look for `\"Normalized data for the following tables:\"` in the trace output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f5d632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started at 2025-07-04 16:31:18.693693+00:00 and COMPLETED in 2.21 seconds with 4 steps.\n",
      "Step extract COMPLETED in 0.16 seconds.\n",
      "\n",
      "Load package 1751646679.099534 is EXTRACTED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step normalize COMPLETED in 0.05 seconds.\n",
      "Normalized data for the following tables:\n",
      "- zoomcamp_data: 948 row(s)\n",
      "- _dlt_pipeline_state: 1 row(s)\n",
      "\n",
      "Load package 1751646679.099534 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step load COMPLETED in 1.60 seconds.\n",
      "Pipeline zoomcamp_pipeline load step completed in 1.59 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_tagged_data\n",
      "The qdrant destination used /Users/haozhewang/Desktop/LLMZoomcamp/LLMZoomcamp/HW_DLT_Workshop/db.qdrant location to store data\n",
      "Load package 1751646679.099534 is LOADED and contains no failed jobs\n",
      "\n",
      "Step run COMPLETED in 2.21 seconds.\n",
      "Pipeline zoomcamp_pipeline load step completed in 1.59 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_tagged_data\n",
      "The qdrant destination used /Users/haozhewang/Desktop/LLMZoomcamp/LLMZoomcamp/HW_DLT_Workshop/db.qdrant location to store data\n",
      "Load package 1751646679.099534 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "from dlt.destinations import qdrant\n",
    "\n",
    "qdrant_destination = qdrant(\n",
    "  qd_path=\"/Users/haozhewang/Desktop/LLMZoomcamp/LLMZoomcamp/HW_DLT_Workshop/db.qdrant\", \n",
    ")\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"zoomcamp_pipeline\",\n",
    "    destination=qdrant_destination,\n",
    "    dataset_name=\"zoomcamp_tagged_data\"\n",
    "\n",
    ")\n",
    "load_info = pipeline.run(zoomcamp_data())\n",
    "print(pipeline.last_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc11f7bd",
   "metadata": {},
   "source": [
    "From the trace output, 948 rows were inserted into the `zoomcamp_data` collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f02dd85",
   "metadata": {},
   "source": [
    "## Question 3. Embeddings\n",
    "\n",
    "When inserting the data, an embedding model was used. Which one?\n",
    "\n",
    "You can find this out by inspecting the `meta.json` file created\n",
    "in the target folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990a372c",
   "metadata": {},
   "source": [
    "From the meta.json, `fast-bge-small-en` is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c2d9e4",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://courses.datatalks.club/llm-zoomcamp-2025/homework/dlt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
